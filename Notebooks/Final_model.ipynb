{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CesUrUpUtKTp",
        "outputId": "f49c6796-a099-4093-a92a-da53e0f178f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LDmmEgOtKsO"
      },
      "outputs": [],
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "YB1vxLkYyfFQ",
        "outputId": "6dc38a7e-eae2-480b-d39a-a6d1047148c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68528, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c5d4c266-40f6-4f52-97a9-1d8dc4024a43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sponginess</th>\n",
              "      <th>Wonder level</th>\n",
              "      <th>Crunchiness</th>\n",
              "      <th>Loudness on impact</th>\n",
              "      <th>Meme creativity</th>\n",
              "      <th>Soap slipperiness</th>\n",
              "      <th>Hype root</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.97698</td>\n",
              "      <td>4.33494</td>\n",
              "      <td>10.67282</td>\n",
              "      <td>1.76692</td>\n",
              "      <td>3.22440</td>\n",
              "      <td>51.681460</td>\n",
              "      <td>3.65434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.07824</td>\n",
              "      <td>4.44616</td>\n",
              "      <td>10.56160</td>\n",
              "      <td>1.70716</td>\n",
              "      <td>3.32566</td>\n",
              "      <td>51.563598</td>\n",
              "      <td>3.47672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.02844</td>\n",
              "      <td>4.22372</td>\n",
              "      <td>10.56160</td>\n",
              "      <td>1.64906</td>\n",
              "      <td>3.17460</td>\n",
              "      <td>50.863080</td>\n",
              "      <td>3.47672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.02844</td>\n",
              "      <td>4.22372</td>\n",
              "      <td>10.56160</td>\n",
              "      <td>1.70716</td>\n",
              "      <td>3.17460</td>\n",
              "      <td>45.841581</td>\n",
              "      <td>3.47672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.87572</td>\n",
              "      <td>4.44616</td>\n",
              "      <td>10.45038</td>\n",
              "      <td>1.70716</td>\n",
              "      <td>3.27586</td>\n",
              "      <td>47.126421</td>\n",
              "      <td>3.47672</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5d4c266-40f6-4f52-97a9-1d8dc4024a43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5d4c266-40f6-4f52-97a9-1d8dc4024a43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5d4c266-40f6-4f52-97a9-1d8dc4024a43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Sponginess  Wonder level  ...  Soap slipperiness  Hype root\n",
              "0     7.97698       4.33494  ...          51.681460    3.65434\n",
              "1     8.07824       4.44616  ...          51.563598    3.47672\n",
              "2     8.02844       4.22372  ...          50.863080    3.47672\n",
              "3     8.02844       4.22372  ...          45.841581    3.47672\n",
              "4     7.87572       4.44616  ...          47.126421    3.47672\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Read the cvs file\n",
        "dataset = pd.read_csv('Training.csv')\n",
        "\n",
        "# Print the shape of dataset\n",
        "print(dataset.shape)\n",
        "\n",
        "# Print all the rows of dataset\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFoJa5kMkq2g"
      },
      "outputs": [],
      "source": [
        "# Build sequence \n",
        "def build_sequences(df, target_labels, window=200, stride=20, telescope=100):\n",
        "    # Sanity check to avoid runtime errors\n",
        "    assert window % stride == 0\n",
        "    dataset = []\n",
        "    labels = []\n",
        "    temp_df = df.copy().values\n",
        "    temp_label = df[target_labels].copy().values\n",
        "    padding_len = len(df)%window\n",
        "\n",
        "    if(padding_len != 0):\n",
        "        # Compute padding length\n",
        "        padding_len = window - len(df)%window\n",
        "        padding = np.zeros((padding_len,temp_df.shape[1]), dtype='float64')\n",
        "        temp_df = np.concatenate((padding,df))\n",
        "        padding = np.zeros((padding_len,temp_label.shape[1]), dtype='float64')\n",
        "        temp_label = np.concatenate((padding,temp_label))\n",
        "\n",
        "        assert len(temp_df) % window == 0\n",
        "\n",
        "    for idx in np.arange(0,len(temp_df)-window-telescope,stride):\n",
        "        dataset.append(temp_df[idx:idx+window])\n",
        "        labels.append(temp_label[idx+window:idx+window+telescope])\n",
        "\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "    return dataset, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U5QeKoWJP9X"
      },
      "outputs": [],
      "source": [
        "# Window size\n",
        "window = 300\n",
        "# Stride size\n",
        "stride = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU3_acq542V-"
      },
      "outputs": [],
      "source": [
        "target_labels = dataset.columns\n",
        "# Telescope size\n",
        "telescope = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_dsZ1Mb41DH",
        "outputId": "97281fa5-dd38-4297-9d29-ff8ec9e97bdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3418, 300, 7), (3418, 50, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "X, y = build_sequences(dataset, target_labels, window, stride, telescope)\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOQeoWfhioGm",
        "outputId": "b831da87-c7e0-4088-d317-8cd8c1052717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [684 685 686 687 688 689 690 691 692 693] TEST: [0 1 2 3 4 5 6 7 8 9]\n",
            "TRAIN: (2734,) TEST: (684,)\n",
            "TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [684 685 686 687 688 689 690 691 692 693]\n",
            "TRAIN: (2734,) TEST: (684,)\n",
            "TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [1368 1369 1370 1371 1372 1373 1374 1375 1376 1377]\n",
            "TRAIN: (2734,) TEST: (684,)\n",
            "TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [2052 2053 2054 2055 2056 2057 2058 2059 2060 2061]\n",
            "TRAIN: (2735,) TEST: (683,)\n",
            "TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [2735 2736 2737 2738 2739 2740 2741 2742 2743 2744]\n",
            "TRAIN: (2735,) TEST: (683,)\n"
          ]
        }
      ],
      "source": [
        "# Apply 5-fold cross validation\n",
        "kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
        "indexes = kf.split(X,y)\n",
        "for train_index, test_index in indexes:\n",
        "    print(\"TRAIN:\", train_index[:10], \"TEST:\", test_index[:10])\n",
        "    print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AASFwzzCCGNn"
      },
      "outputs": [],
      "source": [
        "# Set input shape\n",
        "input_shape = X.shape[1:]\n",
        "# Set output shape\n",
        "output_shape = y.shape[1:]\n",
        "# Set the batch size\n",
        "batch_size = 64\n",
        "# Set the number of epochs for training\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP_H1wc_CGK5"
      },
      "outputs": [],
      "source": [
        "# Build the Bidirectional recurrent neural network\n",
        "def build_CONV_Bidirectional_model(input_shape, output_shape):\n",
        "    # Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    convlstm = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True))(input_layer)\n",
        "    convlstm = tfkl.Conv1D(128, 3, padding='same', activation='relu')(convlstm)\n",
        "    convlstm = tfkl.MaxPool1D()(convlstm)\n",
        "    convlstm = tfkl.Bidirectional(tfkl.LSTM(128, return_sequences=True))(convlstm)\n",
        "    convlstm = tfkl.Conv1D(256, 3, padding='same', activation='relu')(convlstm)\n",
        "    convlstm = tfkl.GlobalAveragePooling1D()(convlstm)\n",
        "    convlstm = tfkl.Dropout(.5)(convlstm)\n",
        "\n",
        "    dense = tfkl.Dense(output_shape[-1]*output_shape[-2], activation='relu')(convlstm)\n",
        "    output_layer = tfkl.Reshape((output_shape[-2],output_shape[-1]))(dense)\n",
        "    output_layer = tfkl.Conv1D(output_shape[-1], 1, padding='same')(output_layer)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(), metrics=['mae', 'mse'])\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtQF53W46A0z"
      },
      "outputs": [],
      "source": [
        "mse = []\n",
        "mae = []\n",
        "models = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eIM0f0SCGF3",
        "outputId": "8ff5d7dd-bad4-4234-ffdc-b20d938ea974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 19s 303ms/step - loss: 98.6793 - mae: 7.4429 - mse: 98.6793 - val_loss: 79.3723 - val_mae: 6.2819 - val_mse: 79.3723 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 68.6954 - mae: 5.9103 - mse: 68.6954 - val_loss: 69.5924 - val_mae: 5.4330 - val_mse: 69.5924 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 59.1840 - mae: 5.1250 - mse: 59.1840 - val_loss: 65.0043 - val_mae: 4.8765 - val_mse: 65.0043 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 55.1162 - mae: 4.7535 - mse: 55.1162 - val_loss: 64.2620 - val_mae: 4.7764 - val_mse: 64.2620 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 51.6480 - mae: 4.4823 - mse: 51.6480 - val_loss: 64.1142 - val_mae: 4.7985 - val_mse: 64.1142 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 48.6552 - mae: 4.2488 - mse: 48.6552 - val_loss: 62.6332 - val_mae: 4.5925 - val_mse: 62.6332 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 46.0925 - mae: 4.0856 - mse: 46.0925 - val_loss: 59.2368 - val_mae: 4.5614 - val_mse: 59.2368 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 42.6261 - mae: 3.9410 - mse: 42.6261 - val_loss: 52.5167 - val_mae: 4.0801 - val_mse: 52.5167 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 37.8947 - mae: 3.7298 - mse: 37.8947 - val_loss: 44.0586 - val_mae: 3.7419 - val_mse: 44.0586 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 34.4645 - mae: 3.5562 - mse: 34.4645 - val_loss: 42.6161 - val_mae: 3.6815 - val_mse: 42.6161 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 33.0232 - mae: 3.5047 - mse: 33.0232 - val_loss: 42.0365 - val_mae: 3.6931 - val_mse: 42.0365 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 30.3881 - mae: 3.3705 - mse: 30.3881 - val_loss: 37.5417 - val_mae: 3.4825 - val_mse: 37.5417 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 28.4294 - mae: 3.2665 - mse: 28.4294 - val_loss: 35.2390 - val_mae: 3.3413 - val_mse: 35.2390 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 26.7748 - mae: 3.1867 - mse: 26.7748 - val_loss: 37.6738 - val_mae: 3.5937 - val_mse: 37.6738 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 8s 217ms/step - loss: 26.1314 - mae: 3.1859 - mse: 26.1314 - val_loss: 34.3286 - val_mae: 3.2686 - val_mse: 34.3286 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 8s 217ms/step - loss: 24.6253 - mae: 3.0890 - mse: 24.6253 - val_loss: 34.2673 - val_mae: 3.2850 - val_mse: 34.2673 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 24.6549 - mae: 3.0977 - mse: 24.6549 - val_loss: 32.2014 - val_mae: 3.2174 - val_mse: 32.2013 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 23.5035 - mae: 3.0234 - mse: 23.5035 - val_loss: 31.4820 - val_mae: 3.2228 - val_mse: 31.4820 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 22.7507 - mae: 2.9886 - mse: 22.7507 - val_loss: 28.7469 - val_mae: 3.0790 - val_mse: 28.7469 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 22.1474 - mae: 2.9681 - mse: 22.1474 - val_loss: 30.8881 - val_mae: 3.1084 - val_mse: 30.8881 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 21.3508 - mae: 2.9142 - mse: 21.3508 - val_loss: 29.9999 - val_mae: 3.1500 - val_mse: 29.9999 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 21.3125 - mae: 2.9158 - mse: 21.3125 - val_loss: 30.2929 - val_mae: 3.2536 - val_mse: 30.2929 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 8s 217ms/step - loss: 20.4768 - mae: 2.8607 - mse: 20.4768 - val_loss: 28.3181 - val_mae: 2.9990 - val_mse: 28.3181 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 20.1956 - mae: 2.8622 - mse: 20.1956 - val_loss: 27.2029 - val_mae: 2.9741 - val_mse: 27.2029 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 19.6084 - mae: 2.8294 - mse: 19.6084 - val_loss: 28.2077 - val_mae: 3.0482 - val_mse: 28.2077 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 8s 217ms/step - loss: 19.4230 - mae: 2.8085 - mse: 19.4230 - val_loss: 29.2628 - val_mae: 3.1078 - val_mse: 29.2628 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 18.7458 - mae: 2.7573 - mse: 18.7458 - val_loss: 26.7272 - val_mae: 3.0145 - val_mse: 26.7272 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 18.6107 - mae: 2.7605 - mse: 18.6107 - val_loss: 26.0951 - val_mae: 2.9151 - val_mse: 26.0951 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 8s 217ms/step - loss: 18.3292 - mae: 2.7392 - mse: 18.3292 - val_loss: 25.8527 - val_mae: 2.9065 - val_mse: 25.8528 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 17.7800 - mae: 2.7077 - mse: 17.7800 - val_loss: 27.3895 - val_mae: 2.9480 - val_mse: 27.3895 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 17.5939 - mae: 2.7116 - mse: 17.5939 - val_loss: 27.4026 - val_mae: 3.0593 - val_mse: 27.4026 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 17.2136 - mae: 2.6819 - mse: 17.2135 - val_loss: 27.5816 - val_mae: 2.9785 - val_mse: 27.5816 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 16.8380 - mae: 2.6427 - mse: 16.8380 - val_loss: 26.8586 - val_mae: 2.9880 - val_mse: 26.8586 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 16.4665 - mae: 2.6199 - mse: 16.4665 - val_loss: 27.8539 - val_mae: 2.9614 - val_mse: 27.8539 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 8s 215ms/step - loss: 16.0138 - mae: 2.5923 - mse: 16.0138 - val_loss: 26.1311 - val_mae: 2.8450 - val_mse: 26.1311 - lr: 5.0000e-04\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 15.0499 - mae: 2.5247 - mse: 15.0499 - val_loss: 26.2936 - val_mae: 2.9019 - val_mse: 26.2936 - lr: 5.0000e-04\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 14.7912 - mae: 2.5202 - mse: 14.7912 - val_loss: 26.5577 - val_mae: 2.9084 - val_mse: 26.5577 - lr: 5.0000e-04\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 14.2114 - mae: 2.4821 - mse: 14.2114 - val_loss: 27.0427 - val_mae: 2.9037 - val_mse: 27.0427 - lr: 5.0000e-04\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 14.1384 - mae: 2.4754 - mse: 14.1384 - val_loss: 27.3780 - val_mae: 2.8714 - val_mse: 27.3780 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses, lstm_cell_22_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8785b60290> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8785b60d90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86fda2aa10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86fda240d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 17s 274ms/step - loss: 194.4276 - mae: 10.6589 - mse: 194.4276 - val_loss: 130.8956 - val_mae: 9.7766 - val_mse: 130.8956 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 9s 223ms/step - loss: 135.8594 - mae: 9.3032 - mse: 135.8594 - val_loss: 100.8351 - val_mae: 7.8861 - val_mse: 100.8351 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 88.1662 - mae: 6.9090 - mse: 88.1662 - val_loss: 80.0136 - val_mae: 6.1525 - val_mse: 80.0136 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 61.9210 - mae: 5.2954 - mse: 61.9210 - val_loss: 71.8943 - val_mae: 5.5793 - val_mse: 71.8943 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 50.4010 - mae: 4.5751 - mse: 50.4010 - val_loss: 68.5426 - val_mae: 5.2228 - val_mse: 68.5426 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 44.2391 - mae: 4.1674 - mse: 44.2391 - val_loss: 63.1876 - val_mae: 4.6898 - val_mse: 63.1877 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 41.7682 - mae: 4.0135 - mse: 41.7682 - val_loss: 63.5153 - val_mae: 5.0928 - val_mse: 63.5153 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 39.7913 - mae: 3.9305 - mse: 39.7913 - val_loss: 58.2968 - val_mae: 4.4629 - val_mse: 58.2968 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 37.2478 - mae: 3.8015 - mse: 37.2478 - val_loss: 53.1576 - val_mae: 4.3487 - val_mse: 53.1576 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 34.4873 - mae: 3.6457 - mse: 34.4873 - val_loss: 50.8634 - val_mae: 4.2510 - val_mse: 50.8634 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 31.9101 - mae: 3.5495 - mse: 31.9101 - val_loss: 48.8996 - val_mae: 4.1023 - val_mse: 48.8996 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 30.1465 - mae: 3.4617 - mse: 30.1465 - val_loss: 44.0090 - val_mae: 3.9628 - val_mse: 44.0090 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 28.0746 - mae: 3.3586 - mse: 28.0746 - val_loss: 42.2983 - val_mae: 3.7607 - val_mse: 42.2983 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 27.1276 - mae: 3.3251 - mse: 27.1276 - val_loss: 40.9918 - val_mae: 3.6635 - val_mse: 40.9918 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 25.7220 - mae: 3.2493 - mse: 25.7220 - val_loss: 39.2710 - val_mae: 3.6351 - val_mse: 39.2710 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 23.7907 - mae: 3.1108 - mse: 23.7907 - val_loss: 36.8331 - val_mae: 3.6587 - val_mse: 36.8331 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 23.5164 - mae: 3.0971 - mse: 23.5164 - val_loss: 34.7199 - val_mae: 3.5070 - val_mse: 34.7199 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 22.9352 - mae: 3.0481 - mse: 22.9352 - val_loss: 34.8830 - val_mae: 3.3888 - val_mse: 34.8830 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 9s 218ms/step - loss: 22.0626 - mae: 3.0253 - mse: 22.0626 - val_loss: 33.5092 - val_mae: 3.3512 - val_mse: 33.5092 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 21.3400 - mae: 2.9701 - mse: 21.3401 - val_loss: 32.9125 - val_mae: 3.3885 - val_mse: 32.9125 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 8s 216ms/step - loss: 20.7260 - mae: 2.9207 - mse: 20.7260 - val_loss: 33.6513 - val_mae: 3.5297 - val_mse: 33.6513 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 8s 216ms/step - loss: 21.1752 - mae: 2.9367 - mse: 21.1752 - val_loss: 36.8201 - val_mae: 3.4577 - val_mse: 36.8201 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 8s 216ms/step - loss: 20.8359 - mae: 2.9178 - mse: 20.8359 - val_loss: 30.2518 - val_mae: 3.1969 - val_mse: 30.2518 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 19.7089 - mae: 2.8575 - mse: 19.7089 - val_loss: 30.4579 - val_mae: 3.2431 - val_mse: 30.4579 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 19.2453 - mae: 2.8104 - mse: 19.2453 - val_loss: 30.2279 - val_mae: 3.1735 - val_mse: 30.2279 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 19.0415 - mae: 2.7990 - mse: 19.0415 - val_loss: 31.9111 - val_mae: 3.2709 - val_mse: 31.9111 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 18.7670 - mae: 2.7653 - mse: 18.7670 - val_loss: 32.2266 - val_mae: 3.1735 - val_mse: 32.2266 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 18.0468 - mae: 2.7258 - mse: 18.0468 - val_loss: 30.1243 - val_mae: 3.0947 - val_mse: 30.1243 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 17.8893 - mae: 2.6998 - mse: 17.8893 - val_loss: 29.4196 - val_mae: 3.1423 - val_mse: 29.4196 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 17.6461 - mae: 2.6907 - mse: 17.6461 - val_loss: 30.7224 - val_mae: 3.1328 - val_mse: 30.7224 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 17.7977 - mae: 2.6913 - mse: 17.7977 - val_loss: 30.6581 - val_mae: 3.2654 - val_mse: 30.6581 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 17.5188 - mae: 2.6833 - mse: 17.5188 - val_loss: 30.0608 - val_mae: 3.0997 - val_mse: 30.0608 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 16.5206 - mae: 2.6042 - mse: 16.5206 - val_loss: 29.8389 - val_mae: 3.1015 - val_mse: 29.8389 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 16.6424 - mae: 2.6133 - mse: 16.6424 - val_loss: 29.5262 - val_mae: 3.0556 - val_mse: 29.5262 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 15.4576 - mae: 2.5454 - mse: 15.4576 - val_loss: 28.2503 - val_mae: 3.0158 - val_mse: 28.2503 - lr: 5.0000e-04\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 14.7384 - mae: 2.4878 - mse: 14.7384 - val_loss: 27.4498 - val_mae: 2.9571 - val_mse: 27.4498 - lr: 5.0000e-04\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 14.8057 - mae: 2.4925 - mse: 14.8057 - val_loss: 28.4730 - val_mae: 3.0635 - val_mse: 28.4730 - lr: 5.0000e-04\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 14.6175 - mae: 2.4835 - mse: 14.6175 - val_loss: 27.8690 - val_mae: 2.9463 - val_mse: 27.8690 - lr: 5.0000e-04\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 14.2210 - mae: 2.4542 - mse: 14.2210 - val_loss: 28.9412 - val_mae: 3.0432 - val_mse: 28.9412 - lr: 5.0000e-04\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 14.1167 - mae: 2.4329 - mse: 14.1167 - val_loss: 28.7475 - val_mae: 3.0829 - val_mse: 28.7475 - lr: 5.0000e-04\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 14.1083 - mae: 2.4437 - mse: 14.1083 - val_loss: 28.3891 - val_mae: 3.0246 - val_mse: 28.3891 - lr: 5.0000e-04\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 13.6385 - mae: 2.4162 - mse: 13.6385 - val_loss: 28.0195 - val_mae: 3.0279 - val_mse: 28.0195 - lr: 2.5000e-04\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 12.9859 - mae: 2.3703 - mse: 12.9859 - val_loss: 28.2225 - val_mae: 3.0082 - val_mse: 28.2225 - lr: 2.5000e-04\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 12.9786 - mae: 2.3697 - mse: 12.9786 - val_loss: 28.3890 - val_mae: 3.0327 - val_mse: 28.3890 - lr: 2.5000e-04\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 12.7909 - mae: 2.3563 - mse: 12.7909 - val_loss: 28.7489 - val_mae: 3.0666 - val_mse: 28.7489 - lr: 2.5000e-04\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 12.9036 - mae: 2.3628 - mse: 12.9036 - val_loss: 28.9104 - val_mae: 3.0241 - val_mse: 28.9104 - lr: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses, lstm_cell_28_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86fdb1c550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86fd0e8090> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f870043d590> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8700440a90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 18s 276ms/step - loss: 162.0054 - mae: 9.3018 - mse: 162.0054 - val_loss: 111.5579 - val_mae: 7.7493 - val_mse: 111.5579 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 9s 227ms/step - loss: 101.4950 - mae: 7.5645 - mse: 101.4951 - val_loss: 90.7514 - val_mae: 6.6788 - val_mse: 90.7514 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 63.2126 - mae: 5.6859 - mse: 63.2126 - val_loss: 74.8160 - val_mae: 5.6767 - val_mse: 74.8160 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 9s 225ms/step - loss: 45.8343 - mae: 4.5628 - mse: 45.8343 - val_loss: 67.9946 - val_mae: 5.1854 - val_mse: 67.9946 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 40.0712 - mae: 4.1163 - mse: 40.0712 - val_loss: 66.3936 - val_mae: 5.0329 - val_mse: 66.3936 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 9s 222ms/step - loss: 37.8812 - mae: 3.9128 - mse: 37.8812 - val_loss: 65.6685 - val_mae: 5.1213 - val_mse: 65.6684 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 36.6204 - mae: 3.8117 - mse: 36.6204 - val_loss: 63.0095 - val_mae: 4.8626 - val_mse: 63.0095 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 34.9225 - mae: 3.7065 - mse: 34.9225 - val_loss: 58.1770 - val_mae: 4.6893 - val_mse: 58.1770 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 31.2927 - mae: 3.5431 - mse: 31.2927 - val_loss: 50.3515 - val_mae: 4.3951 - val_mse: 50.3515 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 29.2054 - mae: 3.4196 - mse: 29.2054 - val_loss: 46.8476 - val_mae: 4.2053 - val_mse: 46.8476 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 27.5196 - mae: 3.3212 - mse: 27.5196 - val_loss: 45.7937 - val_mae: 4.1577 - val_mse: 45.7937 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 25.8160 - mae: 3.2273 - mse: 25.8160 - val_loss: 42.0802 - val_mae: 3.7997 - val_mse: 42.0802 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 24.5891 - mae: 3.1499 - mse: 24.5891 - val_loss: 40.2883 - val_mae: 3.8818 - val_mse: 40.2883 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 23.8401 - mae: 3.1070 - mse: 23.8401 - val_loss: 37.5936 - val_mae: 3.6538 - val_mse: 37.5936 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 23.3763 - mae: 3.0870 - mse: 23.3763 - val_loss: 37.0319 - val_mae: 3.5590 - val_mse: 37.0319 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 22.5461 - mae: 3.0396 - mse: 22.5461 - val_loss: 35.6268 - val_mae: 3.5285 - val_mse: 35.6268 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 22.0940 - mae: 3.0102 - mse: 22.0940 - val_loss: 34.9754 - val_mae: 3.6478 - val_mse: 34.9754 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 20.8794 - mae: 2.9416 - mse: 20.8794 - val_loss: 33.0531 - val_mae: 3.4094 - val_mse: 33.0531 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 20.3553 - mae: 2.9223 - mse: 20.3553 - val_loss: 34.6253 - val_mae: 3.2948 - val_mse: 34.6253 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 9s 219ms/step - loss: 19.9506 - mae: 2.8862 - mse: 19.9506 - val_loss: 34.9435 - val_mae: 3.5483 - val_mse: 34.9435 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 19.7228 - mae: 2.8808 - mse: 19.7228 - val_loss: 32.6572 - val_mae: 3.4345 - val_mse: 32.6572 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 18.9276 - mae: 2.8435 - mse: 18.9276 - val_loss: 33.4835 - val_mae: 3.3214 - val_mse: 33.4835 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 18.7301 - mae: 2.8242 - mse: 18.7301 - val_loss: 32.1763 - val_mae: 3.3832 - val_mse: 32.1763 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 18.0813 - mae: 2.7783 - mse: 18.0813 - val_loss: 30.9993 - val_mae: 3.3491 - val_mse: 30.9993 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 18.4755 - mae: 2.7941 - mse: 18.4755 - val_loss: 33.5021 - val_mae: 3.2874 - val_mse: 33.5021 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 9s 221ms/step - loss: 18.8335 - mae: 2.8218 - mse: 18.8334 - val_loss: 29.4254 - val_mae: 3.3498 - val_mse: 29.4254 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 18.0446 - mae: 2.7788 - mse: 18.0446 - val_loss: 29.0740 - val_mae: 3.2386 - val_mse: 29.0740 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 17.5560 - mae: 2.7554 - mse: 17.5560 - val_loss: 29.9742 - val_mae: 3.2335 - val_mse: 29.9742 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 8s 215ms/step - loss: 17.0233 - mae: 2.7114 - mse: 17.0233 - val_loss: 29.3064 - val_mae: 3.2475 - val_mse: 29.3064 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 8s 215ms/step - loss: 16.6315 - mae: 2.6946 - mse: 16.6315 - val_loss: 29.1674 - val_mae: 3.1779 - val_mse: 29.1674 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 8s 216ms/step - loss: 16.5591 - mae: 2.6818 - mse: 16.5591 - val_loss: 31.4959 - val_mae: 3.6054 - val_mse: 31.4959 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 8s 216ms/step - loss: 16.8597 - mae: 2.7058 - mse: 16.8597 - val_loss: 30.1526 - val_mae: 3.1774 - val_mse: 30.1526 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 8s 216ms/step - loss: 15.3007 - mae: 2.6047 - mse: 15.3007 - val_loss: 28.7716 - val_mae: 3.1872 - val_mse: 28.7716 - lr: 5.0000e-04\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 8s 216ms/step - loss: 14.9021 - mae: 2.5804 - mse: 14.9021 - val_loss: 29.6792 - val_mae: 3.2563 - val_mse: 29.6792 - lr: 5.0000e-04\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 14.7687 - mae: 2.5683 - mse: 14.7687 - val_loss: 29.1784 - val_mae: 3.2368 - val_mse: 29.1784 - lr: 5.0000e-04\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 14.4233 - mae: 2.5481 - mse: 14.4233 - val_loss: 29.1431 - val_mae: 3.2130 - val_mse: 29.1431 - lr: 5.0000e-04\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 14.4575 - mae: 2.5503 - mse: 14.4575 - val_loss: 28.3542 - val_mae: 3.2186 - val_mse: 28.3542 - lr: 5.0000e-04\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 14.0576 - mae: 2.5204 - mse: 14.0576 - val_loss: 28.7359 - val_mae: 3.1512 - val_mse: 28.7359 - lr: 5.0000e-04\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 13.9774 - mae: 2.5175 - mse: 13.9774 - val_loss: 28.6027 - val_mae: 3.2015 - val_mse: 28.6027 - lr: 5.0000e-04\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 13.7185 - mae: 2.4958 - mse: 13.7185 - val_loss: 29.1612 - val_mae: 3.2108 - val_mse: 29.1612 - lr: 5.0000e-04\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 13.7970 - mae: 2.4998 - mse: 13.7970 - val_loss: 29.6119 - val_mae: 3.3074 - val_mse: 29.6119 - lr: 5.0000e-04\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 13.5906 - mae: 2.4865 - mse: 13.5906 - val_loss: 30.0406 - val_mae: 3.2908 - val_mse: 30.0406 - lr: 5.0000e-04\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 13.1018 - mae: 2.4529 - mse: 13.1018 - val_loss: 29.6616 - val_mae: 3.2740 - val_mse: 29.6615 - lr: 2.5000e-04\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 13.0660 - mae: 2.4539 - mse: 13.0660 - val_loss: 29.6929 - val_mae: 3.2995 - val_mse: 29.6929 - lr: 2.5000e-04\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 12.7802 - mae: 2.4360 - mse: 12.7802 - val_loss: 29.5739 - val_mae: 3.2315 - val_mse: 29.5739 - lr: 2.5000e-04\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 12.6633 - mae: 2.4255 - mse: 12.6633 - val_loss: 29.6996 - val_mae: 3.2601 - val_mse: 29.6996 - lr: 2.5000e-04\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 12.5564 - mae: 2.4183 - mse: 12.5564 - val_loss: 29.5877 - val_mae: 3.2104 - val_mse: 29.5877 - lr: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_31_layer_call_fn, lstm_cell_31_layer_call_and_return_conditional_losses, lstm_cell_32_layer_call_fn, lstm_cell_32_layer_call_and_return_conditional_losses, lstm_cell_34_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86fccf3210> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86fc6f9bd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8785f0ce90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f8785ef6a10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 17s 276ms/step - loss: 149.7435 - mae: 8.5851 - mse: 149.7434 - val_loss: 73.0665 - val_mae: 5.6622 - val_mse: 73.0665 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 64.5096 - mae: 5.6519 - mse: 64.5096 - val_loss: 66.9689 - val_mae: 5.1680 - val_mse: 66.9689 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 48.4043 - mae: 4.6440 - mse: 48.4043 - val_loss: 65.8563 - val_mae: 5.0998 - val_mse: 65.8563 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 43.8026 - mae: 4.3391 - mse: 43.8026 - val_loss: 66.0531 - val_mae: 5.0594 - val_mse: 66.0531 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 41.5347 - mae: 4.1768 - mse: 41.5347 - val_loss: 65.8666 - val_mae: 5.1132 - val_mse: 65.8666 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 40.4100 - mae: 4.0773 - mse: 40.4100 - val_loss: 65.3105 - val_mae: 4.9750 - val_mse: 65.3105 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 39.1207 - mae: 3.9939 - mse: 39.1207 - val_loss: 64.4953 - val_mae: 4.8508 - val_mse: 64.4953 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 38.1913 - mae: 3.9195 - mse: 38.1913 - val_loss: 63.6616 - val_mae: 4.9979 - val_mse: 63.6616 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 36.2375 - mae: 3.8187 - mse: 36.2375 - val_loss: 60.9006 - val_mae: 4.7039 - val_mse: 60.9006 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 34.9574 - mae: 3.7487 - mse: 34.9574 - val_loss: 58.8435 - val_mae: 4.8939 - val_mse: 58.8435 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 32.1091 - mae: 3.6186 - mse: 32.1091 - val_loss: 49.2146 - val_mae: 4.2571 - val_mse: 49.2146 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 29.0874 - mae: 3.5044 - mse: 29.0874 - val_loss: 44.7796 - val_mae: 4.3009 - val_mse: 44.7796 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 26.6472 - mae: 3.3738 - mse: 26.6472 - val_loss: 40.3368 - val_mae: 3.9984 - val_mse: 40.3368 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 25.1075 - mae: 3.2788 - mse: 25.1075 - val_loss: 41.0011 - val_mae: 3.9360 - val_mse: 41.0011 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 23.1487 - mae: 3.1561 - mse: 23.1487 - val_loss: 36.9302 - val_mae: 3.8399 - val_mse: 36.9302 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 22.3938 - mae: 3.0960 - mse: 22.3938 - val_loss: 38.3851 - val_mae: 3.8302 - val_mse: 38.3851 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 21.5750 - mae: 3.0506 - mse: 21.5750 - val_loss: 33.8878 - val_mae: 3.6458 - val_mse: 33.8878 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 20.5919 - mae: 2.9644 - mse: 20.5919 - val_loss: 35.7741 - val_mae: 3.6639 - val_mse: 35.7741 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 20.2207 - mae: 2.9525 - mse: 20.2207 - val_loss: 31.6158 - val_mae: 3.4264 - val_mse: 31.6158 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 8s 207ms/step - loss: 19.4594 - mae: 2.8990 - mse: 19.4594 - val_loss: 32.5489 - val_mae: 3.3525 - val_mse: 32.5489 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 18.6793 - mae: 2.8568 - mse: 18.6793 - val_loss: 35.4426 - val_mae: 3.6020 - val_mse: 35.4426 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 8s 208ms/step - loss: 19.0912 - mae: 2.8675 - mse: 19.0912 - val_loss: 31.8469 - val_mae: 3.4027 - val_mse: 31.8469 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 18.1105 - mae: 2.8012 - mse: 18.1105 - val_loss: 31.6770 - val_mae: 3.3634 - val_mse: 31.6770 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 17.5231 - mae: 2.7562 - mse: 17.5231 - val_loss: 31.3839 - val_mae: 3.3624 - val_mse: 31.3839 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 17.0029 - mae: 2.7310 - mse: 17.0029 - val_loss: 30.2112 - val_mae: 3.1683 - val_mse: 30.2112 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 16.4982 - mae: 2.6821 - mse: 16.4982 - val_loss: 29.5840 - val_mae: 3.1108 - val_mse: 29.5840 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 16.7153 - mae: 2.6869 - mse: 16.7153 - val_loss: 29.1922 - val_mae: 3.0813 - val_mse: 29.1922 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 16.4468 - mae: 2.6535 - mse: 16.4468 - val_loss: 29.9300 - val_mae: 3.1098 - val_mse: 29.9300 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 15.6748 - mae: 2.6173 - mse: 15.6748 - val_loss: 30.5058 - val_mae: 3.1294 - val_mse: 30.5058 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 15.8888 - mae: 2.6193 - mse: 15.8888 - val_loss: 35.0112 - val_mae: 3.3254 - val_mse: 35.0112 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 15.3750 - mae: 2.5739 - mse: 15.3750 - val_loss: 29.0281 - val_mae: 3.1391 - val_mse: 29.0281 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 8s 203ms/step - loss: 14.6381 - mae: 2.5254 - mse: 14.6381 - val_loss: 28.9271 - val_mae: 3.0806 - val_mse: 28.9271 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 15.1106 - mae: 2.5557 - mse: 15.1106 - val_loss: 30.1962 - val_mae: 3.0650 - val_mse: 30.1962 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 14.3659 - mae: 2.5045 - mse: 14.3659 - val_loss: 27.2750 - val_mae: 2.9638 - val_mse: 27.2750 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 14.3733 - mae: 2.5024 - mse: 14.3733 - val_loss: 28.4484 - val_mae: 2.9583 - val_mse: 28.4484 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 13.9519 - mae: 2.4522 - mse: 13.9519 - val_loss: 30.1249 - val_mae: 3.0089 - val_mse: 30.1249 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 14.3945 - mae: 2.4821 - mse: 14.3945 - val_loss: 28.2580 - val_mae: 2.9857 - val_mse: 28.2580 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 14.1700 - mae: 2.4565 - mse: 14.1700 - val_loss: 28.6097 - val_mae: 3.0078 - val_mse: 28.6097 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 12.9819 - mae: 2.3922 - mse: 12.9819 - val_loss: 28.3965 - val_mae: 2.9495 - val_mse: 28.3965 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 12.6169 - mae: 2.3610 - mse: 12.6169 - val_loss: 29.9914 - val_mae: 2.9886 - val_mse: 29.9914 - lr: 5.0000e-04\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 12.3340 - mae: 2.3277 - mse: 12.3340 - val_loss: 28.0995 - val_mae: 2.9638 - val_mse: 28.0995 - lr: 5.0000e-04\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 8s 206ms/step - loss: 11.9137 - mae: 2.2997 - mse: 11.9137 - val_loss: 28.2476 - val_mae: 2.8959 - val_mse: 28.2476 - lr: 5.0000e-04\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 8s 204ms/step - loss: 11.8315 - mae: 2.2998 - mse: 11.8315 - val_loss: 27.9263 - val_mae: 2.9087 - val_mse: 27.9263 - lr: 5.0000e-04\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 8s 205ms/step - loss: 11.6104 - mae: 2.2821 - mse: 11.6104 - val_loss: 28.3520 - val_mae: 2.8794 - val_mse: 28.3520 - lr: 5.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_37_layer_call_fn, lstm_cell_37_layer_call_and_return_conditional_losses, lstm_cell_38_layer_call_fn, lstm_cell_38_layer_call_and_return_conditional_losses, lstm_cell_40_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f87006a8d10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f870011b850> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86f35ed910> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86fc7e1f90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 17s 277ms/step - loss: 185.7844 - mae: 9.9982 - mse: 185.7844 - val_loss: 108.8760 - val_mae: 7.7634 - val_mse: 108.8760 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 8s 218ms/step - loss: 145.0207 - mae: 9.2993 - mse: 145.0207 - val_loss: 104.0681 - val_mae: 7.5296 - val_mse: 104.0681 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 9s 220ms/step - loss: 120.1283 - mae: 8.3830 - mse: 120.1283 - val_loss: 98.9158 - val_mae: 7.3484 - val_mse: 98.9158 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 98.4180 - mae: 7.4037 - mse: 98.4180 - val_loss: 94.7448 - val_mae: 7.2151 - val_mse: 94.7448 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 80.6394 - mae: 6.5402 - mse: 80.6394 - val_loss: 90.8334 - val_mae: 7.2049 - val_mse: 90.8334 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 8s 214ms/step - loss: 67.4303 - mae: 5.8664 - mse: 67.4303 - val_loss: 86.5953 - val_mae: 7.0795 - val_mse: 86.5953 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 57.9382 - mae: 5.3578 - mse: 57.9382 - val_loss: 83.3917 - val_mae: 6.9632 - val_mse: 83.3917 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 50.6261 - mae: 4.9259 - mse: 50.6261 - val_loss: 80.8880 - val_mae: 6.9046 - val_mse: 80.8880 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 46.0004 - mae: 4.6232 - mse: 46.0004 - val_loss: 79.5513 - val_mae: 6.8737 - val_mse: 79.5513 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 42.5778 - mae: 4.3677 - mse: 42.5778 - val_loss: 75.9482 - val_mae: 6.6375 - val_mse: 75.9482 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 40.2147 - mae: 4.1561 - mse: 40.2147 - val_loss: 75.4929 - val_mae: 6.6140 - val_mse: 75.4929 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 38.7832 - mae: 4.0062 - mse: 38.7832 - val_loss: 73.0715 - val_mae: 6.4660 - val_mse: 73.0715 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 37.6979 - mae: 3.8872 - mse: 37.6979 - val_loss: 72.2520 - val_mae: 6.4102 - val_mse: 72.2520 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 37.2049 - mae: 3.8160 - mse: 37.2049 - val_loss: 71.0808 - val_mae: 6.3153 - val_mse: 71.0808 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 36.9134 - mae: 3.7771 - mse: 36.9134 - val_loss: 70.3311 - val_mae: 6.2378 - val_mse: 70.3311 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 36.7277 - mae: 3.7420 - mse: 36.7277 - val_loss: 70.0033 - val_mae: 6.2384 - val_mse: 70.0033 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 36.3354 - mae: 3.7095 - mse: 36.3354 - val_loss: 69.2456 - val_mae: 6.1840 - val_mse: 69.2456 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 36.4747 - mae: 3.7143 - mse: 36.4747 - val_loss: 69.1138 - val_mae: 6.1550 - val_mse: 69.1138 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 36.2114 - mae: 3.6831 - mse: 36.2114 - val_loss: 69.4306 - val_mae: 6.1439 - val_mse: 69.4306 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 36.2356 - mae: 3.6819 - mse: 36.2356 - val_loss: 68.5824 - val_mae: 6.1264 - val_mse: 68.5824 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 35.9093 - mae: 3.6727 - mse: 35.9093 - val_loss: 69.3249 - val_mae: 6.1500 - val_mse: 69.3249 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 35.8008 - mae: 3.6663 - mse: 35.8008 - val_loss: 68.2225 - val_mae: 6.1086 - val_mse: 68.2225 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 35.9459 - mae: 3.6811 - mse: 35.9459 - val_loss: 67.6984 - val_mae: 6.0938 - val_mse: 67.6984 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 35.3989 - mae: 3.6602 - mse: 35.3989 - val_loss: 67.7785 - val_mae: 6.1203 - val_mse: 67.7785 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 35.4290 - mae: 3.6609 - mse: 35.4290 - val_loss: 67.0260 - val_mae: 6.1082 - val_mse: 67.0260 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 35.1797 - mae: 3.6605 - mse: 35.1797 - val_loss: 66.6271 - val_mae: 6.1279 - val_mse: 66.6270 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 35.2962 - mae: 3.6692 - mse: 35.2962 - val_loss: 66.4823 - val_mae: 6.1066 - val_mse: 66.4823 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 34.7518 - mae: 3.6312 - mse: 34.7518 - val_loss: 66.9070 - val_mae: 6.0800 - val_mse: 66.9070 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 34.3904 - mae: 3.6229 - mse: 34.3904 - val_loss: 66.1459 - val_mae: 6.0312 - val_mse: 66.1459 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 34.3542 - mae: 3.6327 - mse: 34.3542 - val_loss: 66.2107 - val_mae: 6.1190 - val_mse: 66.2107 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 33.7827 - mae: 3.6033 - mse: 33.7827 - val_loss: 66.1337 - val_mae: 6.0608 - val_mse: 66.1337 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 33.1626 - mae: 3.5767 - mse: 33.1626 - val_loss: 66.3408 - val_mae: 6.1145 - val_mse: 66.3408 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 32.7533 - mae: 3.5845 - mse: 32.7533 - val_loss: 65.2535 - val_mae: 6.0558 - val_mse: 65.2535 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 31.5851 - mae: 3.5349 - mse: 31.5851 - val_loss: 64.7903 - val_mae: 6.0642 - val_mse: 64.7903 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 30.0028 - mae: 3.4668 - mse: 30.0028 - val_loss: 64.4052 - val_mae: 6.0250 - val_mse: 64.4052 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 28.6802 - mae: 3.4035 - mse: 28.6802 - val_loss: 63.7402 - val_mae: 5.9232 - val_mse: 63.7402 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 27.1678 - mae: 3.3373 - mse: 27.1678 - val_loss: 61.6333 - val_mae: 5.8137 - val_mse: 61.6333 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 26.2986 - mae: 3.2855 - mse: 26.2986 - val_loss: 61.7598 - val_mae: 5.8349 - val_mse: 61.7598 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 25.0915 - mae: 3.2278 - mse: 25.0915 - val_loss: 59.4083 - val_mae: 5.7186 - val_mse: 59.4083 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 23.6594 - mae: 3.1447 - mse: 23.6594 - val_loss: 53.9436 - val_mae: 5.4198 - val_mse: 53.9436 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 23.1407 - mae: 3.0927 - mse: 23.1407 - val_loss: 50.1680 - val_mae: 5.1404 - val_mse: 50.1680 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 21.5610 - mae: 3.0016 - mse: 21.5610 - val_loss: 51.8490 - val_mae: 5.2465 - val_mse: 51.8490 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 20.8061 - mae: 2.9557 - mse: 20.8061 - val_loss: 52.2792 - val_mae: 5.1728 - val_mse: 52.2792 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 19.5503 - mae: 2.8687 - mse: 19.5503 - val_loss: 42.7849 - val_mae: 4.6371 - val_mse: 42.7849 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 18.8837 - mae: 2.8178 - mse: 18.8837 - val_loss: 42.8388 - val_mae: 4.6246 - val_mse: 42.8388 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 18.0684 - mae: 2.7727 - mse: 18.0684 - val_loss: 41.1983 - val_mae: 4.4935 - val_mse: 41.1983 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 18.1177 - mae: 2.7686 - mse: 18.1177 - val_loss: 40.0540 - val_mae: 4.3704 - val_mse: 40.0540 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 17.3327 - mae: 2.7214 - mse: 17.3327 - val_loss: 38.1415 - val_mae: 4.2657 - val_mse: 38.1415 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 16.8429 - mae: 2.6804 - mse: 16.8429 - val_loss: 37.6753 - val_mae: 4.0328 - val_mse: 37.6753 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "39/39 [==============================] - 8s 209ms/step - loss: 16.2455 - mae: 2.6363 - mse: 16.2455 - val_loss: 43.0939 - val_mae: 4.2957 - val_mse: 43.0939 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 16.2395 - mae: 2.6361 - mse: 16.2395 - val_loss: 38.9105 - val_mae: 4.2019 - val_mse: 38.9105 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 15.9677 - mae: 2.6218 - mse: 15.9677 - val_loss: 35.0460 - val_mae: 3.8799 - val_mse: 35.0460 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 15.9602 - mae: 2.6087 - mse: 15.9602 - val_loss: 36.1949 - val_mae: 3.9407 - val_mse: 36.1949 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 15.7913 - mae: 2.6019 - mse: 15.7913 - val_loss: 36.3139 - val_mae: 3.9629 - val_mse: 36.3139 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 15.4686 - mae: 2.5818 - mse: 15.4686 - val_loss: 36.9065 - val_mae: 3.9733 - val_mse: 36.9065 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 15.2096 - mae: 2.5612 - mse: 15.2096 - val_loss: 35.0722 - val_mae: 3.9000 - val_mse: 35.0722 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 14.5437 - mae: 2.5197 - mse: 14.5437 - val_loss: 35.1079 - val_mae: 3.8252 - val_mse: 35.1079 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 13.9834 - mae: 2.4819 - mse: 13.9834 - val_loss: 35.1209 - val_mae: 3.7332 - val_mse: 35.1209 - lr: 5.0000e-04\n",
            "Epoch 59/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 13.5921 - mae: 2.4506 - mse: 13.5921 - val_loss: 33.9393 - val_mae: 3.7321 - val_mse: 33.9392 - lr: 5.0000e-04\n",
            "Epoch 60/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 13.3733 - mae: 2.4432 - mse: 13.3733 - val_loss: 34.7013 - val_mae: 3.8237 - val_mse: 34.7013 - lr: 5.0000e-04\n",
            "Epoch 61/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 12.9371 - mae: 2.4091 - mse: 12.9371 - val_loss: 34.5731 - val_mae: 3.8061 - val_mse: 34.5731 - lr: 5.0000e-04\n",
            "Epoch 62/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 13.0563 - mae: 2.4156 - mse: 13.0563 - val_loss: 35.5016 - val_mae: 3.8038 - val_mse: 35.5016 - lr: 5.0000e-04\n",
            "Epoch 63/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 12.8439 - mae: 2.4094 - mse: 12.8439 - val_loss: 34.6260 - val_mae: 3.7531 - val_mse: 34.6260 - lr: 5.0000e-04\n",
            "Epoch 64/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 12.5955 - mae: 2.3793 - mse: 12.5955 - val_loss: 36.3505 - val_mae: 3.8052 - val_mse: 36.3505 - lr: 5.0000e-04\n",
            "Epoch 65/200\n",
            "39/39 [==============================] - 8s 213ms/step - loss: 12.2927 - mae: 2.3592 - mse: 12.2927 - val_loss: 35.8437 - val_mae: 3.8230 - val_mse: 35.8437 - lr: 2.5000e-04\n",
            "Epoch 66/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 11.9944 - mae: 2.3358 - mse: 11.9944 - val_loss: 37.5047 - val_mae: 3.8508 - val_mse: 37.5047 - lr: 2.5000e-04\n",
            "Epoch 67/200\n",
            "39/39 [==============================] - 8s 210ms/step - loss: 12.0986 - mae: 2.3414 - mse: 12.0986 - val_loss: 34.8677 - val_mae: 3.7173 - val_mse: 34.8677 - lr: 2.5000e-04\n",
            "Epoch 68/200\n",
            "39/39 [==============================] - 8s 211ms/step - loss: 12.0585 - mae: 2.3400 - mse: 12.0585 - val_loss: 35.8919 - val_mae: 3.7942 - val_mse: 35.8919 - lr: 2.5000e-04\n",
            "Epoch 69/200\n",
            "39/39 [==============================] - 8s 212ms/step - loss: 12.0333 - mae: 2.3410 - mse: 12.0333 - val_loss: 37.4093 - val_mae: 3.8175 - val_mse: 37.4093 - lr: 2.5000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_43_layer_call_fn, lstm_cell_43_layer_call_and_return_conditional_losses, lstm_cell_44_layer_call_fn, lstm_cell_44_layer_call_and_return_conditional_losses, lstm_cell_46_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86fbba36d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86ff91ba50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86fbbd8150> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f86f39450d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "k = 0\n",
        "for train_index, test_index in kf.split(X,y):\n",
        "  k = k + 1\n",
        "  # Instantiate the neural network\n",
        "  model = build_CONV_Bidirectional_model(input_shape, output_shape)\n",
        "  \n",
        "  # Train the model\n",
        "  history = model.fit(\n",
        "      x = X[train_index],\n",
        "      y = y[train_index],\n",
        "      batch_size = batch_size,\n",
        "      epochs = epochs,\n",
        "      validation_split=.1,\n",
        "      callbacks = [\n",
        "          # Early Stopping\n",
        "          tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
        "          # Method to reduce learning rate when a metric has stopped improving\n",
        "          tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n",
        "      ]\n",
        "  ).history\n",
        "\n",
        "  # Start the prediction\n",
        "  predictions = model.predict(X[test_index])\n",
        "  \n",
        "  # Print mean squared error for each step\n",
        "  mean_squared_error = tfk.metrics.mse(y[test_index].flatten(),predictions.flatten())\n",
        "  \n",
        "  # Print mean absolute error for each step\n",
        "  mean_absolute_error = tfk.metrics.mae(y[test_index].flatten(),predictions.flatten())\n",
        "  \n",
        "  mse.append(mean_squared_error) \n",
        "  mae.append(mean_absolute_error)\n",
        "  models.append(model)\n",
        "  \n",
        "  # Save the five models, one for each step of cross validation. Only the model with \n",
        "  # the best rmse will be submitted in Codalab. We notice that the best model \n",
        "  # gave a better perfomance on Codalab then the one retrained on the entire dataset.\n",
        "  model.save('Bidirectional_tel50_ver' + str(k))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWDZPHNM4o1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32ed20c-d485-46fb-d2e3-0632055acf57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55.298748\n",
            "19.436071\n",
            "35.455498\n",
            "22.377926\n",
            "40.232815\n",
            "4.796805\n",
            "2.8483741\n",
            "3.6275663\n",
            "2.6400597\n",
            "3.7797348\n"
          ]
        }
      ],
      "source": [
        "# Cross validation, with this data, is pessimistically biased. Indeed the rmse score \n",
        "# given by this fit is worse than the score given by submission in Codelab.\n",
        "\n",
        "# Print the mean squared error for each model\n",
        "for m1 in mse:\n",
        "  print(m1.numpy())\n",
        "# Print the mean absolute error for each model\n",
        "for m2 in mae:\n",
        "  print(m2.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAJvc3Uiz1HQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60982746-32a5-4bac-f186-0d87374e9e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse average:  34.56021\n",
            "rmse average:  5.8787937\n",
            "mae average:  3.538508\n"
          ]
        }
      ],
      "source": [
        "# Compute the mean of mse for the models\n",
        "mse_cv = tf.math.reduce_mean(mse)\n",
        "\n",
        "# Compute the mean of rmse for the models\n",
        "rmse_cv = tf.math.sqrt(mse_cv.numpy())\n",
        "\n",
        "# Compute the mean of mae for the models\n",
        "mae_cv = tf.math.reduce_mean(mae)\n",
        "\n",
        "print('mse average: ', mse_cv.numpy())\n",
        "print('rmse average: ', rmse_cv.numpy())\n",
        "print('mae average: ', mae_cv.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Ensemble"
      ],
      "metadata": {
        "id": "wbefla-6qh97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During this phase we also tried a Model Ensemble approach. We started by increasing the window size, searching for a good score on the train set and a poor one on the test phase. Once obtained this overfitting models we averaged the 5 predictions. This approach gave us worse results then the single model, probably because the models were still too similar to each other."
      ],
      "metadata": {
        "id": "_DE6Bzmcpug5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "46hSsAV4prMx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Final_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}